{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image,load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Width=128\n",
    "Image_Height=128\n",
    "Image_Size=(Image_Width,Image_Height)\n",
    "Image_Channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat.0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat.1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat.10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat.100.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat.1000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>dog.9995.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>dog.9996.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>dog.9997.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>dog.9998.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>dog.9999.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename  category\n",
       "0         cat.0.jpg         0\n",
       "1         cat.1.jpg         0\n",
       "2        cat.10.jpg         0\n",
       "3       cat.100.jpg         0\n",
       "4      cat.1000.jpg         0\n",
       "...             ...       ...\n",
       "24995  dog.9995.jpg         1\n",
       "24996  dog.9996.jpg         1\n",
       "24997  dog.9997.jpg         1\n",
       "24998  dog.9998.jpg         1\n",
       "24999  dog.9999.jpg         1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames=os.listdir(\"extracted_images\")\n",
    "\n",
    "categories=[]\n",
    "for f_name in filenames:\n",
    "    category=f_name.split('.')[0]\n",
    "    if category=='dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "\n",
    "df=pd.DataFrame({\n",
    "    'filename':filenames,\n",
    "    'category':categories\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating The Model by using Neural Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,\\\n",
    "     Dropout,Flatten,Dense,Activation,\\\n",
    "     BatchNormalization\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(Image_Width,Image_Height,Image_Channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "  optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 126, 126, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 63, 63, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 63, 63, 32)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 61, 61, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 28, 28, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               12845568  \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12942786 (49.37 MB)\n",
      "Trainable params: 12941314 (49.37 MB)\n",
      "Non-trainable params: 1472 (5.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',patience=2,verbose=1,factor=0.5,min_lr=0.00001)\n",
    "callbacks=[earlystop,learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category']=df['category'].replace({0:'cat',1:'dog'})\n",
    "train_df, validate_df =train_test_split(df,test_size=0.20,random_state=42)\n",
    "train_df   =train_df.reset_index(drop=True)\n",
    "validate_df=validate_df.reset_index(drop=True)\n",
    "total_train= train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Found 20000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15,rescale=1./255,shear_range=0.1,zoom_range=0.2,\n",
    "                                   horizontal_flip=True,width_shift_range=0.1,height_shift_range=0.1)\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\"./extracted_images/\",x_col='filename',y_col='category',\n",
    "                                                    target_size = Image_Size,class_mode='categorical',batch_size=batch_size)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(validate_df, \"./extracted_images\", x_col='filename',y_col='category',\n",
    "                                                              target_size=Image_Size,class_mode='categorical',batch_size=batch_size)\n",
    "test_datagen = ImageDataGenerator(rotation_range=15,rescale=1./255,shear_range=0.1,zoom_range=0.2,horizontal_flip=True,width_shift_range=0.1,height_shift_range=0.1)\n",
    "test_generator = train_datagen.flow_from_dataframe(train_df, \"./extracted_images/\",x_col='filename',y_col='category',target_size=Image_Size,\n",
    "                                                 class_mode='categorical',batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nikhil\\AppData\\Local\\Temp\\ipykernel_21420\\2528005629.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.7476 - accuracy: 0.6338WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 553s 413ms/step - loss: 0.7476 - accuracy: 0.6338 - val_loss: 0.5841 - val_accuracy: 0.7171 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.5565 - accuracy: 0.7246WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 534s 401ms/step - loss: 0.5565 - accuracy: 0.7246 - val_loss: 0.5192 - val_accuracy: 0.7506 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.4978 - accuracy: 0.7659WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 392s 294ms/step - loss: 0.4978 - accuracy: 0.7659 - val_loss: 0.6040 - val_accuracy: 0.7580 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.4682 - accuracy: 0.7817WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 325s 244ms/step - loss: 0.4682 - accuracy: 0.7817 - val_loss: 0.4025 - val_accuracy: 0.8134 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.4461 - accuracy: 0.7946WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 342s 257ms/step - loss: 0.4461 - accuracy: 0.7946 - val_loss: 0.3886 - val_accuracy: 0.8284 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.4238 - accuracy: 0.8074WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 344s 258ms/step - loss: 0.4238 - accuracy: 0.8074 - val_loss: 0.4926 - val_accuracy: 0.7788 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.4030 - accuracy: 0.8181WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 348s 261ms/step - loss: 0.4030 - accuracy: 0.8181 - val_loss: 0.3776 - val_accuracy: 0.8326 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.8260WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 338s 254ms/step - loss: 0.3862 - accuracy: 0.8260 - val_loss: 0.5391 - val_accuracy: 0.8140 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.8364WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 316s 237ms/step - loss: 0.3777 - accuracy: 0.8364 - val_loss: 1.7056 - val_accuracy: 0.5778 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.3691 - accuracy: 0.8372WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 354s 265ms/step - loss: 0.3691 - accuracy: 0.8372 - val_loss: 0.3195 - val_accuracy: 0.8671 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nikhil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"model_catsVSdogs_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir(\"./test1\")\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1334/1334 [==============================] - 174s 131ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_generator, steps=test_generator.n // test_generator.batch_size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['category'] = np.argmax(predictions, axis=-1)\n",
    "\n",
    "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
    "test_df['category'] = test_df['category'].replace(label_map)\n",
    "\n",
    "test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x2400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_test = test_df.head(18)\n",
    "sample_test.head()\n",
    "\n",
    "plt.figure(figsize=(12, 24))\n",
    "for index, row in sample_test.iterrows():\n",
    "    filename = str(row['filename'])\n",
    "    category = row['category']\n",
    "\n",
    "    # Skip if filename is 'nan'\n",
    "    if filename == 'nan':\n",
    "        continue\n",
    "\n",
    "    img_path = \"./test1/\" + filename\n",
    "\n",
    "    try:\n",
    "        img = load_img(img_path,filename, target_size=Image_Size)\n",
    "        plt.subplot(6, 3, index+1)\n",
    "        plt.imshow(img)\n",
    "        plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {img_path}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "Prediction for x.0.jpg: cat\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Prediction for x.1.jpg: dog\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Prediction for y.1.jpg: cat\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "results = {0: 'cat', 1: 'dog'}\n",
    "\n",
    "# Assuming you have a list of image filenames\n",
    "image_filenames = [\"x.0.jpg\", \"x.1.jpg\", \"y.1.jpg\"]\n",
    "\n",
    "for filename in image_filenames:\n",
    "    img_path = \"./test1/\" + filename\n",
    "\n",
    "    try:\n",
    "        im = Image.open(img_path)\n",
    "        im = im.resize(Image_Size)\n",
    "        im = np.expand_dims(im, axis=0)\n",
    "        im = np.array(im)\n",
    "        im = im / 255\n",
    "        pred_probabilities = model.predict([im])[0]\n",
    "        pred_class = np.argmax(pred_probabilities)\n",
    "        print(f\"Prediction for {filename}: {results[pred_class]}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {img_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
